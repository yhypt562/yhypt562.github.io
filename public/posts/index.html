<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>AI交流</title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="description" content="">
    <meta name="generator" content="Hugo 0.115.4">
    
    
    
    
      <meta name="robots" content="noindex, nofollow">
    

    
<link rel="stylesheet" href="/ananke/css/main.min.css" >



    
    
    
      

    

    
    
      <link href="/posts/index.xml" rel="alternate" type="application/rss+xml" title="AI交流" />
      <link href="/posts/index.xml" rel="feed" type="application/rss+xml" title="AI交流" />
      
    
    
    <meta property="og:title" content="Posts" />
<meta property="og:description" content="" />
<meta property="og:type" content="website" />
<meta property="og:url" content="http://blog.tdcloud.xyz/posts/" />
<meta itemprop="name" content="Posts">
<meta itemprop="description" content=""><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Posts"/>
<meta name="twitter:description" content=""/>

	
  </head>

  <body class="ma0 avenir bg-near-white">

    

  <header>
    <div class="pb3-m pb6-l bg-black">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l justify-between items-center center">
    <a href="/" class="f3 fw2 hover-white no-underline white-90 dib">
      
        AI交流
      
    </a>
    <div class="flex-l items-center">
      

      
      
<div class="ananke-socials">
  
</div>

    </div>
  </div>
</nav>

      <div class="tc-l pv3 ph3 ph4-ns">
        <h1 class="f2 f-subheadline-l fw2 light-silver mb0 lh-title">
          Posts
        </h1>
        
      </div>
    </div>
  </header>


    <main class="pb7" role="main">
      
  <article class="pa3 pa4-ns nested-copy-line-height">
    <section class="cf ph3 ph5-l pv3 pv4-l f4 tc-l center measure-wide lh-copy mid-gray"></section>
    <section class="flex-ns flex-wrap justify-around mt5">
      
        <div class="relative w-100 w-30-l mb4 bg-white">
          <div class="relative w-100 mb4 bg-white nested-copy-line-height">
  <div class="bg-white mb3 pa4 gray overflow-hidden">
    <span class="f6 db">Posts</span>
    <h1 class="f3 near-black">
      <a href="/posts/chatgpt-02/" class="link black dim">
        Chatgpt提示词教程
      </a>
    </h1>
    <div class="nested-links f5 lh-copy nested-copy-line-height">
      课程地址 https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/
Guideline（提示指南） 在本课程中，您将练习两个提示原则及其相关策略，以便为大型语言模型编写有效的提示。
设置 加载API密钥和相关的Python库。 import openai import os from dotenv import load_dotenv, find_dotenv _ = load_dotenv(find_dotenv()) openai.api_key = os.getenv(&#39;OPENAI_API_KEY&#39;) def get_completion(prompt, model=&#34;gpt-3.5-turbo&#34;): messages = [{&#34;role&#34;: &#34;user&#34;, &#34;content&#34;: prompt}] response = openai.ChatCompletion.create( model=model, messages=messages, temperature=0, # this is the degree of randomness of the model&#39;s output ) return response.choices[0].message[&#34;content&#34;] 提示词原则 原则 1：编写清晰特定的说明
原则 2：给模型时间“思考”
原则 1：编写清晰特定的说明 策略 1：使用特定的分隔符，清楚的指示出输入（指令和待处理的文本）的不同部分 分隔符可以是：
​```, &#34;&#34;&#34;, &lt; &gt;, `&lt;tag&gt; &lt;/tag&gt;`, `:` 代码
text = f&#34;&#34;&#34; 您应该通过 \ 表达您希望模型执行的操作 提供清晰且\ 尽可能具体。 \ 这将引导模型达到所需的输出，\ 并减少收到不相关\ 或不正确的反应。 不要混淆写一个 \ 通过编写简短提示来清除提示。 \ 在许多情况下，更长的提示更清晰 \ 和模型的上下文，这可能导致 \ 更详细和相关的输出。 &#34;&#34;&#34; prompt = f&#34;&#34;&#34; 总结由三重反引号分隔的文本 \ 成一个句子。 ​```{text}``` &#34;&#34;&#34; response = get_completion(prompt) print(response) 结果
    </div>
  </div>
</div>

        </div>
      
        <div class="relative w-100 w-30-l mb4 bg-white">
          <div class="relative w-100 mb4 bg-white nested-copy-line-height">
  <div class="bg-white mb3 pa4 gray overflow-hidden">
    <span class="f6 db">Posts</span>
    <h1 class="f3 near-black">
      <a href="/posts/chatpgt-01/" class="link black dim">
        ChatGPT原理——驾校“AI教练”教导学员
      </a>
    </h1>
    <div class="nested-links f5 lh-copy nested-copy-line-height">
      最近ChatGPT是非常火啊，我一个“爱学习的”大码程序员都怦然心动，来蹭热度了。我赶紧就把 OpenAI 以往的 GPT-N 系列论文又翻出来，认真领会大语言模型（Large Language Model）的强大之处。经过一个多月的认真研究，查阅了几十篇相关的论文，终于在写这篇文章之前，熟练掌握了26个英文字母。
前段时间ChatGPT火起来后，就去看过很多大V的文章，简单了解了这个AI是咋回事。大部分人都在说GPT还是有很多不足，例如：
回答无效问题：它只是根据之前的训练数据进行模式匹配和预测，随机抽取概率高的文字来回答，而没有真正理解人类想要的答案。 缺乏可解释性：它很难进行深入的逻辑推理或解决需要多步骤操作的问题。因此，对于这类问题，GPT-3的回答可能不准确或含糊。 提供虚假回答：它的训练数据中可能包含错误、虚假或误导性的信息，因此它可能会生成不准确或有误导性的回答。 内容偏见问题：如果在训练数据中接触到偏见或歧视性的内容，它可能在生成回答时重复或放大这些偏见。这可能导致生成具有偏见或不公平观点的回答。 这些问题是如何产生的呢？下面我们带着问题，一步一步来看ChatGPT具体如何来做的。
为什么会有这样的问题？——无监督预训练（网上自学） 首先我们来看看为什么会出现这些问题，ChatGPT的核心是LLM，也就是大家常说到的大语言模型，而这种模型的核心就是为给定文本计算出后面出现的字的概率，举个通熟易懂的例子，如下：
编辑切换为居中
LLM大语言模型特点
输入一句“隔壁老”，它后面可能的下一个字是“王”、“张”或“李”。因为在前面的学习训练的结果中，这些字词出现的概率相对较高；语言模型实际上能够评估给定先前序列的每个可能词的可能性。例如隔壁老王，应该概率会比较高。回家看看你家有几个隔壁老王。哈哈😃
我再举几个例子：
寡妇门前_________ 大概率会是：“寡妇门前是非多” 天使的脸蛋，魔鬼的_____ 大概率会是：“魔鬼的身材”
那我们LLM就只能做文字接龙了吗？那这样的模型是不是就只有这一点价值了呢？也不能这样说，可以通过一些小技巧，也是可以得到一些答案的。例如下面的场景：
请问“四川最高的山是哪一座？”让GPT给出这句话后面的一个字：“贡”；然后再让GPT给出“四川最高的山是哪一座？贡”这句话的的后面一个字，可能是：“嘎”；接着让GPT给出“四川最高的山是哪一座？贡嘎”后面一个字，可能大概率就是“山”了。
编辑切换为居中
提问回答过程
经过这样一个过程，还是有很大概率得出人类想要的答案的。
ChatGPT如何改进的 前面提到了GPT是一个预测后续概率的模型，GPT也不知道哪些回答是人类想要的。比如问 GPT “四川省最高的山是哪座山？”，可能的回答就有多种，例如：“我也不知道，你能告诉我吗”、“贡嘎山”、“四姑娘山”或“你猜猜看” 都是上下文通顺的回答，但很显然 “贡嘎山”才 是更符合人类期望的回答。对于这种情况，GPT就只能随机选择一个或是几个答案了。所以OpenAI的方案是采用RLHF（人类反馈的强化学习）来进行训练，具体包括以下三个不同的步骤：
编辑切换为居中
ChatGPT训练步骤
具体步骤：
收集数据并进行监督学习（“老司机”掌握方向） 收集对比数据并训练奖励模型（给AI找个“教练”） 使用 PPO 强化学习算法针对奖励模型进行优化（AI“教练”指导 AI） 第一步：“老司机”掌握方向（有监督训练初始模型） ChatGPT前一阶段，是采用无监督训练的，采用了网上的没有经过人类标记处理的数据，直接对ChatGPT进行训练。这样得到的模型，由于这些数据的来源五花八门，造成了回答不能满足人类需求的情况。
为了解决这种情况，研究人员让人类“AI培训师”从问题集中的抽取一些问题，丢给GPT3.5，让它给出答案。“AI培训师”再根据GPT3.5给出答案，然后进行人工修正，再把这些人类修正认可的问题和答案丢给 GPT3.5去学习。通过这种有训练的方法，我们就得到一个简易版的 ChatGPT 模型。也就是SFT，三伏天模型。😄
编辑切换为居中
收集数据并进行监督学习过程
讲到这里，就有人会问了，“AI培训师”毕竟是少数，怎么能穷尽所有的问题呢？实际上只需要提供数万条数据给AI就行，因为 GPT3.5 本来就有能力生成出正确答案，只是它不知道哪些答案是人类真正需要的。
第二步：给AI找个“教练”（收集对比数据并训练奖励模型） 编辑切换为居中
AI 教练
针对上一步，只要“AI培训师”人数足够多，理论上已经可以达到目的：训练出效果很好且符合人类偏好的模型。
若是全用人工，就算是能全部标记完，成本也是天文数字。这绝对不是一个好的解决方案。那又要通过什么办法来解决的呢？
大家记得前几年轰动一时的围棋人工智能 AlphaGo吧，它是通过海量的自我对弈优化模型，最终超越人类；那我们能不能让 GPT也通过大量对话练习提升其回答问题的能力呢？答案是可以，但还缺少一个来判断好坏的裁判或是老师。
对于AlphaGo下围棋来说，胜负是通过围棋的规则来决定；但 GPT 回答一个问题，那谁来告诉 GPT 回答的好坏呢？要是也用人来进行判断，那就回到了刚刚的问题，不可能全部答案都由人来进行判断。
如果有个能辨别 GPT 回答好坏的“教练模型”（即 Reward 模型），并按照人类的评分标准对 GPT 所给出的答案进行评分，那不就能帮助 GPT 的回答更加符合人类的偏好了么？
    </div>
  </div>
</div>

        </div>
      
        <div class="relative w-100 w-30-l mb4 bg-white">
          <div class="relative w-100 mb4 bg-white nested-copy-line-height">
  <div class="bg-white mb3 pa4 gray overflow-hidden">
    <span class="f6 db">Posts</span>
    <h1 class="f3 near-black">
      <a href="/posts/centos-bbr/" class="link black dim">
        CentOS7安装新版内核和开启BBR加速
      </a>
    </h1>
    <div class="nested-links f5 lh-copy nested-copy-line-height">
      设置安装内核 查看当前服务器的内核版本。
uname -sr uname命令用于打印当前系统相关信息（内核版本号、硬件架构、主机名称和操作系统类型等）。
-a或--all：显示全部的信息； -m或--machine：显示电脑类型； -n或-nodename：显示在网络上的主机名称； -r或--release：显示操作系统的发行编号； -s或--sysname：显示操作系统名称； -v：显示操作系统的版本； -p或--processor：输出处理器类型或&#34;unknown&#34;； -i或--hardware-platform：输出硬件平台或&#34;unknown&#34;； -o或--operating-system：输出操作系统名称； --help：显示帮助； --version：显示版本信息。 BBR内核要求是4.9+，通常来说你通过上面这个命令出来的内核版本是在3.几。接下来启用 ELRepo 仓库
rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org rpm -Uvh https://www.elrepo.org/elrepo-release-7.0-3.el7.elrepo.noarch.rpm 然后安装新版的稳定版内核
yum --enablerepo=elrepo-kernel install kernel-ml -y 安装完毕后使用下面的命令查看是否安装成功。
rpm -qa | grep kernel 我的显示如下：
kernel-3.10.0-862.14.4.el7.x86_64 kernel-ml-5.3.8-1.el7.elrepo.x86_64 kernel-3.10.0-1062.4.1.el7.x86_64 kernel-headers-3.10.0-1062.4.1.el7.x86_64 kernel-3.10.0-957.5.1.el7.x86_64 kernel-3.10.0-1062.1.2.el7.x86_64 kernel-tools-3.10.0-1062.4.1.el7.x86_64 kernel-tools-libs-3.10.0-1062.4.1.el7.x86_64 kernel-3.10.0-957.1.3.el7.x86_64 里面kernel-ml-5.3.8-1.el7.elrepo.x86_64就是安装的新版版本内核（你看到这篇教程的时候可能内核版本有变化，随机应变）
接下来需要设置系统启动顺序，使用下面的命令。
sudo egrep ^menuentry /etc/grub2.cfg | cut -f 2 -d \&#39; 我的显示如下：
CentOS Linux (5.3.8-1.el7.elrepo.x86_64) 7 (Core) CentOS Linux (3.10.0-1062.4.1.el7.x86_64) 7 (Core) CentOS Linux (3.
    </div>
  </div>
</div>

        </div>
      
    </section></article>

    </main>
    <footer class="bg-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href="http://blog.tdcloud.xyz/" >
    &copy;  AI交流 2023 
  </a>
    <div>
<div class="ananke-socials">
  
</div>
</div>
  </div>
</footer>

  </body>
</html>
